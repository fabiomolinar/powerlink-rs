use super::state::{CnInfo, CnState, MnContext};
use crate::frame::basic::MacAddress;
use crate::frame::{DllMsEvent, RequestedServiceId};
use crate::nmt::events::{NmtCommand, NmtEvent};
use crate::nmt::{NmtStateMachine, states::NmtState};
use crate::od::ObjectValue;
use crate::types::{C_ADR_MN_DEF_NODE_ID, NodeId};
use log::{debug, error, info, trace, warn};

/// Looks up a CN's MAC address from the Object Dictionary (0x2100).
/// This is a custom object, not defined by the spec, but used in the examples.
pub(super) fn get_cn_mac_address(context: &MnContext, node_id: NodeId) -> Option<MacAddress> {
    const IDX_MAN_CN_MAC_ADDRESS_LIST: u16 = 0x2100;
    
    match context
        .core
        .od
        .read(IDX_MAN_CN_MAC_ADDRESS_LIST, node_id.0)
    {
        Some(cow) => match &*cow {
            ObjectValue::OctetString(bytes) => {
                if bytes.len() == 6 {
                    // Create a [u8; 6] from the Vec
                    let mut mac_bytes = [0u8; 6];
                    mac_bytes.copy_from_slice(bytes);
                    if mac_bytes != [0u8; 6] {
                        Some(MacAddress(mac_bytes))
                    } else {
                        None // All zeros is not a valid MAC for this
                    }
                } else {
                    warn!(
                        "Invalid MAC address length for Node {} in OD 0x2100. Expected 6 bytes, got {}.",
                        node_id.0,
                        bytes.len()
                    );
                    None
                }
            }
            _ => {
                error!(
                    "Invalid data type for OD 0x2100 sub-index {}. Expected OctetString.",
                    node_id.0
                );
                None
            }
        },
        None => {
            error!(
                "Could not find entry for Node {} in OD 0x2100 (MAC address map).",
                node_id.0
            );
            None
        }
    }
}


/// Determines the highest priority asynchronous action to be taken.
/// The priority is:
// ... (existing code)
pub(super) fn determine_next_async_action(
    context: &mut MnContext,
) -> (RequestedServiceId, NodeId, bool) {
    // 1. Check for pending Exception Reset requests (highest priority).
    if let Some(node_to_reset) = context.pending_er_requests.pop() {
        info!("[MN] Prioritizing ER for Node {}.", node_to_reset.0);
        return (RequestedServiceId::StatusRequest, node_to_reset, true);
    }

    // 2. Check for pending StatusRequests due to error signaling.
    if let Some(node_to_query) = context.pending_status_requests.pop() {
        info!(
            "[MN] Prioritizing StatusRequest for Node {} due to error signal.",
            node_to_query.0
        );
        return (RequestedServiceId::StatusRequest, node_to_query, false);
    }

    // 3. Check for pending NMT commands generated by the MN.
    if !context.pending_nmt_commands.is_empty() {
        info!("[MN] Prioritizing internal NMT command for async slot.");
        return (
            RequestedServiceId::UnspecifiedInvite,
            NodeId(C_ADR_MN_DEF_NODE_ID),
            false,
        );
    }

    // 4. Check for pending generic async frames from the MN application.
    if !context.mn_async_send_queue.is_empty() {
        info!("[MN] Prioritizing MN-initiated generic async frame for async slot.");
        return (
            RequestedServiceId::UnspecifiedInvite,
            NodeId(C_ADR_MN_DEF_NODE_ID),
            false,
        );
    }

    // 5. Check for pending SDO client requests from the MN's new stateful manager.
    // FIX: (E0609) Replaced pending_sdo_client_requests with sdo_client_manager
    if let Some((target_node_id, _seq, _cmd)) = context.sdo_client_manager.get_pending_request(
        context.current_cycle_start_time_us, // Use a current time
        &context.core.od,
    ) {
        info!(
            "[MN] Prioritizing MN-initiated SDO request to Node {} for async slot.",
            target_node_id.0
        );
        return (
            RequestedServiceId::UnspecifiedInvite,
            NodeId(C_ADR_MN_DEF_NODE_ID), // MN sends the request
            false,
        );
    }

    // 6. Check for nodes to identify (next priority)
    if let Some(node_to_poll) = find_next_node_to_identify(context) {
        return (RequestedServiceId::IdentRequest, node_to_poll, false);
    }

    // 7. Check for async-only nodes to poll
    if let Some(node_to_poll) = find_next_async_only_to_poll(context) {
        return (RequestedServiceId::StatusRequest, node_to_poll, false);
    }

    // 8. Service pending ASnd requests from CNs (already in priority order from BinaryHeap)
    if let Some(request) = context.async_request_queue.pop() {
        info!(
            "[MN] Granting async slot to Node {} (PR={})",
            request.node_id.0, request.priority
        );
        let service_id = if request.priority == 7 {
            RequestedServiceId::NmtRequestInvite
        } else {
            RequestedServiceId::UnspecifiedInvite
        };
        return (service_id, request.node_id, false);
    }

    // 9. If nothing else to do, send a SoA with NoService
    (RequestedServiceId::NoService, NodeId(0), false)
}

/// Checks if MN can transition NMT state based on mandatory CN states.
pub(super) fn check_bootup_state(context: &mut MnContext) {
    let current_mn_state = context.nmt_state_machine.current_state();

    if current_mn_state == NmtState::NmtPreOperational1 {
        // Check if all mandatory nodes are Identified or further, but not Missing or Stopped
        let all_mandatory_identified = context.mandatory_nodes.iter().all(|node_id| {
            let state = context
                .node_info
                .get(node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // Updated condition: >= Identified AND <= Operational
            state >= CnState::Identified && state <= CnState::Operational
        });

        if all_mandatory_identified {
            info!("[MN] All mandatory nodes identified. Triggering NMT transition to PreOp2.");
            // NMT_MT3
            context
                .nmt_state_machine
                .process_event(NmtEvent::AllCnsIdentified, &mut context.core.od);

            // --- Phase 1.4: BOOT_STEP2 ---
            // Now that we are in PreOp2, queue NMTEnableReadyToOperate for all identified CNs.
            // (Spec 7.4.1.4, 7.4.2.2.2)
            for (node_id, info) in context.node_info.iter() {
                if info.state == CnState::Identified {
                    info!(
                        "[MN] BOOT_STEP2: Queuing NMTEnableReadyToOperate for Node {}.",
                        node_id.0
                    );
                    context
                        .pending_nmt_commands
                        .push((NmtCommand::EnableReadyToOperate, *node_id));
                }
            }
        }
    } else if current_mn_state == NmtState::NmtPreOperational2 {
        // Check if all mandatory nodes are PreOperational or further (ReadyToOp reported via PRes/Status)
        let all_mandatory_preop = context.mandatory_nodes.iter().all(|node_id| {
            let state = context
                .node_info
                .get(node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // CN reports PreOp2 or ReadyToOp, MN maps this to CnState::PreOperational
            // Also check <= Operational to ensure node hasn't gone missing/stopped
            state >= CnState::PreOperational && state <= CnState::Operational
        });

        if all_mandatory_preop {
            // Check MN startup flags if application trigger is needed
            // NMT_StartUp_U32.Bit8 = 0 -> Auto transition
            if context.nmt_state_machine.startup_flags & (1 << 8) == 0 {
                info!(
                    "[MN] All mandatory nodes PreOperational/ReadyToOp. Triggering NMT transition to ReadyToOp."
                );
                // NMT_MT4
                context.nmt_state_machine.process_event(
                    NmtEvent::ConfigurationCompleteCnsReady,
                    &mut context.core.od,
                );
            } else {
                debug!(
                    "[MN] All mandatory nodes PreOperational/ReadyToOp, but waiting for application trigger to enter ReadyToOp."
                );
            }
        }
    } else if current_mn_state == NmtState::NmtReadyToOperate {
        // --- Phase 1.5: CHECK_COMMUNICATION ---
        // Check if all mandatory nodes have passed communication checks (Spec 7.4.1.5)
        let all_mandatory_comm_checked = context.mandatory_nodes.iter().all(|node_id| {
            context
                .node_info
                .get(node_id)
                .is_some_and(|info| info.communication_ok) // This field will be added in state.rs
        });

        if all_mandatory_comm_checked {
            // Check MN startup flags if application trigger is needed
            // NMT_StartUp_U32.Bit2 = 0 -> Auto transition
            if context.nmt_state_machine.startup_flags & (1 << 2) == 0 {
                info!(
                    "[MN] CHECK_COMMUNICATION passed for all mandatory nodes. Triggering NMT transition to Operational."
                );
                // NMT_MT5 - Use AllMandatoryCnsOperational event as the trigger
                context
                    .nmt_state_machine
                    .process_event(NmtEvent::AllMandatoryCnsOperational, &mut context.core.od);
            } else {
                debug!(
                    "[MN] All mandatory nodes passed CHECK_COMMUNICATION, but waiting for application trigger to enter Operational."
                );
            }
        }
    }
    // No automatic checks needed in Operational state based on CN states alone.
}

/// Finds the next configured CN that has not been identified yet for polling.
pub(super) fn find_next_node_to_identify(context: &mut MnContext) -> Option<NodeId> {
    // Start iterating from the node *after* the last one polled
    let start_node_id_val = context.last_ident_poll_node_id.0.wrapping_add(1);

    let mut wrapped_around = false;
    let mut current_node_id_val = start_node_id_val;

    loop {
        // Handle wrap-around and node ID range (1-239 for CNs)
        if current_node_id_val == 0 || current_node_id_val > 239 {
            current_node_id_val = 1;
        }
        if current_node_id_val == start_node_id_val {
            if wrapped_around {
                debug!("[MN] Full circle check for unidentified nodes completed.");
                break; // Full circle, no nodes found
            }
            wrapped_around = true;
        }

        // Ensure NodeId::try_from is used or logic handles invalid IDs
        let node_id = NodeId(current_node_id_val); // Directly create NodeId

        // Check if this node ID exists in our configured node state map
        // AND if its current state is Unknown or Missing.
        let info = context.node_info.get(&node_id).cloned(); // Use cloned()
        if matches!(
            info,
            Some(CnInfo {
                state: CnState::Unknown,
                ..
            }) | Some(CnInfo {
                state: CnState::Missing,
                ..
            })
        ) {
            // Found a node to poll
            debug!(
                "[MN] Found unidentified or missing Node {} to poll.",
                node_id.0
            );
            context.last_ident_poll_node_id = node_id;
            return Some(node_id);
        }

        current_node_id_val = current_node_id_val.wrapping_add(1);
    }

    debug!("[MN] No more unidentified nodes found.");
    None // No unidentified nodes left
}

/// Finds the next async-only CN that needs a status poll.
pub(super) fn find_next_async_only_to_poll(context: &mut MnContext) -> Option<NodeId> {
    if context.async_only_nodes.is_empty() {
        return None;
    }

    // Find the index of the last polled node to continue from there
    let start_idx = context
        .async_only_nodes
        .iter()
        .position(|&id| id == context.last_status_poll_node_id)
        .map_or(0, |i| (i + 1) % context.async_only_nodes.len());

    // Iterate through the async-only list in a round-robin fashion
    for i in 0..context.async_only_nodes.len() {
        let current_idx = (start_idx + i) % context.async_only_nodes.len();
        let node_id = context.async_only_nodes[current_idx];

        // Poll any async-only node that is not considered completely gone
        if let Some(info) = context.node_info.get(&node_id) {
            if info.state != CnState::Missing {
                debug!(
                    "[MN] Found async-only Node {} to poll for status.",
                    node_id.0
                );
                context.last_status_poll_node_id = node_id;
                return Some(node_id);
            }
        }
    }

    None
}

/// Gets the Node ID of the next isochronous node to poll for the given multiplex cycle.
/// Returns None if all nodes for the current cycle have been polled.
/// This function modifies the internal `next_isoch_node_idx`.
pub(super) fn get_next_isochronous_node_to_poll(
    context: &mut MnContext,
    current_multiplex_cycle: u8,
) -> Option<NodeId> {
    // Iterate through the pre-defined list starting from the current index
    while context.next_isoch_node_idx < context.isochronous_nodes.len() {
        let node_id = context.isochronous_nodes[context.next_isoch_node_idx];
        context.next_isoch_node_idx += 1; // Move to the next index for the *next* call

        // Check if this node should be polled in the current multiplex cycle
        let assigned_cycle = context.multiplex_assign.get(&node_id).copied().unwrap_or(0);
        // Corrected multiplex check: cycle counter is 0-based, assigned is 1-based
        let should_poll_this_cycle = assigned_cycle == 0 // Continuous node
            || (context.multiplex_cycle_len > 0 && assigned_cycle == (current_multiplex_cycle + 1)); // Multiplexed node for this cycle (assigned cycle is 1-based)

        if should_poll_this_cycle {
            // Check if the node is in a state where it should be polled isochronously
            let state = context
                .node_info
                .get(&node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // Poll nodes from Identified onwards, excluding Stopped/Missing
            // PReq allowed in PreOp2, ReadyToOp, Operational
            // Corrected state check: >= PreOperational
            if state >= CnState::PreOperational {
                // Found a valid node to poll in this cycle
                trace!(
                    "[MN] Polling Node {} (State: {:?}, MuxCycle: {}) in mux cycle {}",
                    node_id.0, state, assigned_cycle, current_multiplex_cycle
                );
                return Some(node_id);
            } else {
                debug!(
                    "[MN] Skipping Node {} (State: {:?}) in isochronous polling for mux cycle {}.",
                    node_id.0, state, current_multiplex_cycle
                );
            }
        } else {
            trace!(
                "[MN] Skipping Node {} (assigned mux cycle {}) in current mux cycle {}.",
                node_id.0, assigned_cycle, current_multiplex_cycle
            );
        }
        // If the node is not in a pollable state or not for this cycle, the loop continues
    }
    None // No more nodes left to poll in this cycle
}

/// Helper to check if there are more isochronous nodes to poll in the current cycle.
/// Does not modify `next_isoch_node_idx`.
pub(super) fn has_more_isochronous_nodes(context: &MnContext, current_multiplex_cycle: u8) -> bool {
    // Check remaining nodes in the list from the current index
    for idx in context.next_isoch_node_idx..context.isochronous_nodes.len() {
        let node_id = context.isochronous_nodes[idx];
        let assigned_cycle = context.multiplex_assign.get(&node_id).copied().unwrap_or(0);
        // Corrected multiplex check
        let should_poll_this_cycle = assigned_cycle == 0
            || (context.multiplex_cycle_len > 0 && assigned_cycle == (current_multiplex_cycle + 1));

        if should_poll_this_cycle {
            let state = context
                .node_info
                .get(&node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // Corrected state check: >= PreOperational
            if state >= CnState::PreOperational {
                return true; // Found at least one more node to poll
            }
        }
    }
    false // No more pollable nodes found for this cycle
}

/// Schedules a timeout check.
/// This function was missing.
pub(super) fn schedule_timeout(context: &mut MnContext, deadline_us: u64, event: DllMsEvent) {
    trace!(
        "[MN] Scheduling timeout event {:?} for {}us",
        event,
        deadline_us
    );
    context.pending_timeout_event = Some(event);
    // Only set if this deadline is sooner than any existing one
    match context.next_tick_us {
        Some(existing_deadline) if deadline_us < existing_deadline => {
            context.next_tick_us = Some(deadline_us);
        }
        None => {
            context.next_tick_us = Some(deadline_us);
        }
        _ => {} // Existing deadline is sooner
    }
}