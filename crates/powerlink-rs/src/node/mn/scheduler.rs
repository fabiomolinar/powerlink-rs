// crates/powerlink-rs/src/node/mn/scheduler.rs
use super::payload;
use super::state::{CnInfo, CnState, MnContext};
use crate::frame::basic::MacAddress;
use crate::frame::{DllMsEvent, PowerlinkFrame, RequestedServiceId, ServiceId}; // Added ServiceId/Frame
use crate::nmt::events::{MnNmtCommandRequest, NmtEvent, NmtStateCommand};
use crate::nmt::{NmtStateMachine, states::NmtState};
use crate::node::mn::ip_from_node_id;
use crate::node::mn::state::NmtCommandData;
use crate::types::{C_ADR_MN_DEF_NODE_ID, NodeId};
use log::{debug, info, trace};

/// Looks up a CN's MAC address from the dynamic ARP cache.
/// The cache is populated passively by `IdentResponse` frames.
pub(super) fn get_cn_mac_address(context: &MnContext, node_id: NodeId) -> Option<MacAddress> {
    // 1. Derive the IP address from the Node ID.
    let ip_addr = ip_from_node_id(node_id);

    // 2. Look up the IP in the ARP cache.
    match context.arp_cache.get(&ip_addr) {
        Some(mac) => Some(*mac),
        None => {
            // Log this as trace, as it's normal during boot-up before IdentResponse.
            trace!(
                "Could not find MAC address for Node {} (IP {}) in ARP cache.",
                node_id.0,
                core::net::Ipv4Addr::from(ip_addr)
            );
            None
        }
    }
}

/// Determines the highest priority asynchronous action to be taken.
pub(super) fn determine_next_async_action(
    context: &mut MnContext,
) -> (RequestedServiceId, NodeId, bool) {
    // 1. Check for pending Exception Reset requests (highest priority).
    if let Some(node_to_reset) = context.pending_er_requests.pop() {
        info!("[MN] Prioritizing ER for Node {}.", node_to_reset.0);
        return (RequestedServiceId::StatusRequest, node_to_reset, true);
    }

    // 2. Check for pending StatusRequests due to error signaling.
    if let Some(node_to_query) = context.pending_status_requests.pop() {
        info!(
            "[MN] Prioritizing StatusRequest for Node {} due to error signal.",
            node_to_query.0
        );
        return (RequestedServiceId::StatusRequest, node_to_query, false);
    }

    // 3. Check for pending NMT commands generated by the MN.
    // These are queued as specific commands, so we signal cycle.rs to process the queue.
    if !context.pending_nmt_commands.is_empty() {
        info!("[MN] Prioritizing internal NMT command for async slot.");
        return (
            RequestedServiceId::UnspecifiedInvite,
            NodeId(C_ADR_MN_DEF_NODE_ID),
            false,
        );
    }

    // 4. Check for pending generic async frames from the MN application.
    if !context.mn_async_send_queue.is_empty() {
        info!("[MN] Prioritizing MN-initiated generic async frame for async slot.");
        return (
            RequestedServiceId::UnspecifiedInvite,
            NodeId(C_ADR_MN_DEF_NODE_ID),
            false,
        );
    }

    // 5. Check for pending SDO client requests from the MN's stateful manager.
    // CRITICAL FIX: get_pending_request is stateful. We must CAPTURE the result
    // and queue it, otherwise the frame is lost and the manager hangs.
    if let Some((target_node_id, seq, cmd)) = context
        .sdo_client_manager
        .get_pending_request(context.current_cycle_start_time_us, &context.core.od)
    {
        info!(
            "[MN] Prioritizing MN-initiated SDO request to Node {} for async slot.",
            target_node_id.0
        );

        // Construct the ASnd frame here and push it to the generic queue.
        // This unifies the send path for SDOs and generic frames.
        let sdo_payload = {
            let mut buf = alloc::vec::Vec::with_capacity(128);
            // We ignore serialization errors here as these structs are internal and validated
            let _ = seq.serialize(&mut buf);
            let _ = cmd.serialize(&mut buf);
            buf
        };

        let dest_mac = get_cn_mac_address(context, target_node_id)
            .unwrap_or(MacAddress(crate::types::C_DLL_MULTICAST_ASND));

        let frame = PowerlinkFrame::ASnd(crate::frame::ASndFrame::new(
            context.core.mac_address,
            dest_mac,
            target_node_id,
            NodeId(C_ADR_MN_DEF_NODE_ID),
            ServiceId::Sdo,
            sdo_payload,
        ));

        context.mn_async_send_queue.push(frame);

        return (
            RequestedServiceId::UnspecifiedInvite,
            NodeId(C_ADR_MN_DEF_NODE_ID),
            false,
        );
    }

    // 6. Check for nodes to identify (next priority)
    if let Some(node_to_poll) = find_next_node_to_identify(context) {
        return (RequestedServiceId::IdentRequest, node_to_poll, false);
    }

    // 7. Check for async-only nodes to poll
    if let Some(node_to_poll) = find_next_async_only_to_poll(context) {
        return (RequestedServiceId::StatusRequest, node_to_poll, false);
    }

    // 8. Check for NMT Info Broadcasts (NEW: Background Task)
    // Only if no other frames are queued.
    if context.mn_async_send_queue.is_empty() {
        if let Some(service_id) = context.publish_config.get(&context.current_multiplex_cycle) {
            trace!(
                "[MN] Scheduling NMT Info Broadcast ({:?}) for async slot.",
                service_id
            );

            // Build the frame using payload logic
            let frame = payload::build_nmt_info_frame(context, *service_id);
            context.mn_async_send_queue.push(frame);

            return (
                RequestedServiceId::UnspecifiedInvite,
                NodeId(C_ADR_MN_DEF_NODE_ID),
                false,
            );
        }
    }

    // 9. Service pending ASnd requests from CNs (already in priority order from BinaryHeap)
    if let Some(request) = context.async_request_queue.pop() {
        info!(
            "[MN] Granting async slot to Node {} (PR={})",
            request.node_id.0, request.priority
        );
        let service_id = if request.priority == 7 {
            RequestedServiceId::NmtRequestInvite
        } else {
            RequestedServiceId::UnspecifiedInvite
        };
        return (service_id, request.node_id, false);
    }

    // 10. If nothing else to do, send a SoA with NoService
    (RequestedServiceId::NoService, NodeId(0), false)
}

/// Checks if MN can transition NMT state based on mandatory CN states.
pub(super) fn check_bootup_state(context: &mut MnContext) {
    let current_mn_state = context.nmt_state_machine.current_state();

    if current_mn_state == NmtState::NmtPreOperational1 {
        // Check if all mandatory nodes are Identified or further, but not Missing or Stopped
        let all_mandatory_identified = context.mandatory_nodes.iter().all(|node_id| {
            let state = context
                .node_info
                .get(node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // Updated condition: >= Identified AND <= Operational
            state >= CnState::Identified && state <= CnState::Operational
        });

        if all_mandatory_identified {
            info!("[MN] All mandatory nodes identified. Triggering NMT transition to PreOp2.");
            // NMT_MT3
            context
                .nmt_state_machine
                .process_event(NmtEvent::AllCnsIdentified, &mut context.core.od);

            // --- Phase 1.4: BOOT_STEP2 ---
            // Now that we are in PreOp2, queue NMTEnableReadyToOperate for all identified CNs.
            // (Spec 7.4.1.4, 7.4.2.2.2)
            for (node_id, info) in context.node_info.iter() {
                if info.state == CnState::Identified {
                    info!(
                        "[MN] BOOT_STEP2: Queuing NMTEnableReadyToOperate for Node {}.",
                        node_id.0
                    );
                    context.pending_nmt_commands.push((
                        MnNmtCommandRequest::State(NmtStateCommand::EnableReadyToOperate),
                        *node_id,
                        NmtCommandData::None,
                    ));
                }
            }
        }
    } else if current_mn_state == NmtState::NmtPreOperational2 {
        // Check if all mandatory nodes are PreOperational or further (ReadyToOp reported via PRes/Status)
        let all_mandatory_preop = context.mandatory_nodes.iter().all(|node_id| {
            let state = context
                .node_info
                .get(node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // CN reports PreOp2 or ReadyToOp, MN maps this to CnState::PreOperational
            // Also check <= Operational to ensure node hasn't gone missing/stopped
            state >= CnState::PreOperational && state <= CnState::Operational
        });

        if all_mandatory_preop {
            // Check MN startup flags if application trigger is needed
            // NMT_StartUp_U32.Bit8 = 0 -> Auto transition
            if context.nmt_state_machine.startup_flags & (1 << 8) == 0 {
                info!(
                    "[MN] All mandatory nodes PreOperational/ReadyToOp. Triggering NMT transition to ReadyToOp."
                );
                // NMT_MT4
                context.nmt_state_machine.process_event(
                    NmtEvent::ConfigurationCompleteCnsReady,
                    &mut context.core.od,
                );
            } else {
                debug!(
                    "[MN] All mandatory nodes PreOperational/ReadyToOp, but waiting for application trigger to enter ReadyToOp."
                );
            }
        }
    } else if current_mn_state == NmtState::NmtReadyToOperate {
        // --- Phase 1.5: CHECK_COMMUNICATION ---
        // Check if all mandatory nodes have passed communication checks (Spec 7.4.1.5)
        let all_mandatory_comm_checked = context.mandatory_nodes.iter().all(|node_id| {
            context
                .node_info
                .get(node_id)
                .is_some_and(|info| info.communication_ok)
        });

        if all_mandatory_comm_checked {
            // Check MN startup flags if application trigger is needed
            // NMT_StartUp_U32.Bit2 = 0 -> Auto transition
            if context.nmt_state_machine.startup_flags & (1 << 2) == 0 {
                info!(
                    "[MN] CHECK_COMMUNICATION passed for all mandatory nodes. Triggering NMT transition to Operational."
                );
                // NMT_MT5 - Use AllMandatoryCnsOperational event as the trigger
                context
                    .nmt_state_machine
                    .process_event(NmtEvent::AllMandatoryCnsOperational, &mut context.core.od);
            } else {
                debug!(
                    "[MN] All mandatory nodes passed CHECK_COMMUNICATION, but waiting for application trigger to enter Operational."
                );
            }
        }
    }
    // No automatic checks needed in Operational state based on CN states alone.
}

/// Finds the next configured CN that has not been identified yet for polling.
pub(super) fn find_next_node_to_identify(context: &mut MnContext) -> Option<NodeId> {
    // Start iterating from the node *after* the last one polled
    let start_node_id_val = context.last_ident_poll_node_id.0.wrapping_add(1);

    let mut wrapped_around = false;
    let mut current_node_id_val = start_node_id_val;

    loop {
        // Handle wrap-around and node ID range (1-239 for CNs)
        if current_node_id_val == 0 || current_node_id_val > 239 {
            current_node_id_val = 1;
        }
        if current_node_id_val == start_node_id_val {
            if wrapped_around {
                debug!("[MN] Full circle check for unidentified nodes completed.");
                break; // Full circle, no nodes found
            }
            wrapped_around = true;
        }

        // Ensure NodeId::try_from is used or logic handles invalid IDs
        let node_id = NodeId(current_node_id_val); // Directly create NodeId

        // Check if this node ID exists in our configured node state map
        // AND if its current state is Unknown or Missing.
        let info = context.node_info.get(&node_id).cloned(); // Use cloned()
        if matches!(
            info,
            Some(CnInfo {
                state: CnState::Unknown,
                ..
            }) | Some(CnInfo {
                state: CnState::Missing,
                ..
            })
        ) {
            // Found a node to poll
            debug!(
                "[MN] Found unidentified or missing Node {} to poll.",
                node_id.0
            );
            context.last_ident_poll_node_id = node_id;
            return Some(node_id);
        }

        current_node_id_val = current_node_id_val.wrapping_add(1);
    }

    debug!("[MN] No more unidentified nodes found.");
    None // No unidentified nodes left
}

/// Finds the next async-only CN that needs a status poll.
pub(super) fn find_next_async_only_to_poll(context: &mut MnContext) -> Option<NodeId> {
    if context.async_only_nodes.is_empty() {
        return None;
    }

    // Find the index of the last polled node to continue from there
    let start_idx = context
        .async_only_nodes
        .iter()
        .position(|&id| id == context.last_status_poll_node_id)
        .map_or(0, |i| (i + 1) % context.async_only_nodes.len());

    // Iterate through the async-only list in a round-robin fashion
    for i in 0..context.async_only_nodes.len() {
        let current_idx = (start_idx + i) % context.async_only_nodes.len();
        let node_id = context.async_only_nodes[current_idx];

        // Poll any async-only node that is not considered completely gone
        if let Some(info) = context.node_info.get(&node_id) {
            if info.state != CnState::Missing {
                debug!(
                    "[MN] Found async-only Node {} to poll for status.",
                    node_id.0
                );
                context.last_status_poll_node_id = node_id;
                return Some(node_id);
            }
        }
    }

    None
}

/// Gets the Node ID of the next isochronous node to poll for the given multiplex cycle.
pub(super) fn get_next_isochronous_node_to_poll(
    context: &mut MnContext,
    current_multiplex_cycle: u8,
) -> Option<NodeId> {
    // Iterate through the pre-defined list starting from the current index
    while context.next_isoch_node_idx < context.isochronous_nodes.len() {
        let node_id = context.isochronous_nodes[context.next_isoch_node_idx];
        context.next_isoch_node_idx += 1; // Move to the next index for the *next* call

        // Check if this node should be polled in the current multiplex cycle
        let assigned_cycle = context.multiplex_assign.get(&node_id).copied().unwrap_or(0);
        // Corrected multiplex check: cycle counter is 0-based, assigned is 1-based
        let should_poll_this_cycle = assigned_cycle == 0 // Continuous node
            || (context.multiplex_cycle_len > 0 && assigned_cycle == (current_multiplex_cycle + 1)); // Multiplexed node for this cycle (assigned cycle is 1-based)

        if should_poll_this_cycle {
            // Check if the node is in a state where it should be polled isochronously
            let state = context
                .node_info
                .get(&node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // Poll nodes from Identified onwards, excluding Stopped/Missing
            // Corrected state check: >= PreOperational
            if state >= CnState::PreOperational {
                // Found a valid node to poll in this cycle
                trace!(
                    "[MN] Polling Node {} (State: {:?}, MuxCycle: {}) in mux cycle {}",
                    node_id.0, state, assigned_cycle, current_multiplex_cycle
                );
                return Some(node_id);
            } else {
                debug!(
                    "[MN] Skipping Node {} (State: {:?}) in isochronous polling for mux cycle {}.",
                    node_id.0, state, current_multiplex_cycle
                );
            }
        } else {
            trace!(
                "[MN] Skipping Node {} (assigned mux cycle {}) in current mux cycle {}.",
                node_id.0, assigned_cycle, current_multiplex_cycle
            );
        }
        // If the node is not in a pollable state or not for this cycle, the loop continues
    }
    None // No more nodes left to poll in this cycle
}

/// Helper to check if there are more isochronous nodes to poll in the current cycle.
pub(super) fn has_more_isochronous_nodes(context: &MnContext, current_multiplex_cycle: u8) -> bool {
    // Check remaining nodes in the list from the current index
    for idx in context.next_isoch_node_idx..context.isochronous_nodes.len() {
        let node_id = context.isochronous_nodes[idx];
        let assigned_cycle = context.multiplex_assign.get(&node_id).copied().unwrap_or(0);

        let should_poll_this_cycle = assigned_cycle == 0
            || (context.multiplex_cycle_len > 0 && assigned_cycle == (current_multiplex_cycle + 1));

        if should_poll_this_cycle {
            let state = context
                .node_info
                .get(&node_id)
                .map_or(CnState::Unknown, |info| info.state);
            // Corrected state check: >= PreOperational
            if state >= CnState::PreOperational {
                return true; // Found at least one more node to poll
            }
        }
    }
    false // No more pollable nodes found for this cycle
}

/// Schedules a timeout check.
pub(super) fn schedule_timeout(context: &mut MnContext, deadline_us: u64, event: DllMsEvent) {
    trace!(
        "[MN] Scheduling timeout event {:?} for {}us",
        event, deadline_us
    );
    context.pending_timeout_event = Some(event);
    // Only set if this deadline is sooner than any existing one
    match context.next_tick_us {
        Some(existing_deadline) if deadline_us < existing_deadline => {
            context.next_tick_us = Some(deadline_us);
        }
        None => {
            context.next_tick_us = Some(deadline_us);
        }
        _ => {} // Existing deadline is sooner
    }
}

#[cfg(test)]
mod tests {
    use crate::node::mn::state::AsyncRequest;
    use alloc::collections::{BTreeMap, BinaryHeap};

    use super::*;
    use crate::frame::error::{DllErrorManager, LoggingErrorHandler, MnErrorCounters};
    use crate::frame::ms_state_machine::DllMsStateMachine;
    use crate::nmt::mn_state_machine::MnNmtStateMachine;
    use crate::node::CoreNodeContext;
    use crate::od::ObjectDictionary;
    use crate::sdo::client_manager::SdoClientManager;
    use crate::sdo::transport::AsndTransport;
    #[cfg(feature = "sdo-udp")]
    use crate::sdo::transport::UdpTransport;
    use crate::sdo::{EmbeddedSdoClient, EmbeddedSdoServer, SdoClient, SdoServer};
    use crate::types::{C_ADR_MN_DEF_NODE_ID, NodeId};
    use alloc::vec::Vec;

    // --- Helper to create a minimal MnContext for testing ---
    fn create_test_context<'a>() -> MnContext<'a> {
        let od = ObjectDictionary::new(None);
        let core = CoreNodeContext {
            od,
            mac_address: Default::default(),
            sdo_server: SdoServer::new(),
            sdo_client: SdoClient::new(),
            embedded_sdo_server: EmbeddedSdoServer::new(),
            embedded_sdo_client: EmbeddedSdoClient::new(),
        };

        MnContext {
            core,
            configuration_interface: None,
            nmt_state_machine: MnNmtStateMachine::new(
                NodeId(C_ADR_MN_DEF_NODE_ID),
                Default::default(),
                0,
                0,
            ),
            dll_state_machine: DllMsStateMachine::default(),
            dll_error_manager: DllErrorManager::new(MnErrorCounters::new(), LoggingErrorHandler),
            asnd_transport: AsndTransport,
            #[cfg(feature = "sdo-udp")]
            udp_transport: UdpTransport,
            cycle_time_us: 10000,
            multiplex_cycle_len: 10,
            multiplex_assign: BTreeMap::new(),
            publish_config: BTreeMap::new(),
            current_multiplex_cycle: 0,
            node_info: BTreeMap::new(),
            mandatory_nodes: Vec::new(),
            isochronous_nodes: Vec::new(),
            async_only_nodes: Vec::new(),
            arp_cache: BTreeMap::new(),
            next_isoch_node_idx: 0,
            current_phase: crate::node::mn::state::CyclePhase::Idle,
            current_polled_cn: None,
            async_request_queue: BinaryHeap::new(),
            pending_er_requests: Vec::new(),
            pending_status_requests: Vec::new(),
            pending_nmt_commands: Vec::new(),
            mn_async_send_queue: Vec::new(),
            sdo_client_manager: SdoClientManager::new(),
            last_ident_poll_node_id: NodeId(0),
            last_status_poll_node_id: NodeId(0),
            next_tick_us: None,
            pending_timeout_event: None,
            current_cycle_start_time_us: 0,
            initial_operational_actions_done: false,
        }
    }

    #[test]
    fn test_priority_er_requests() {
        let mut context = create_test_context();
        let node_id = NodeId(10);

        // Setup: Add a pending ER request
        context.pending_er_requests.push(node_id);

        // Act
        let (service, target, er_flag) = determine_next_async_action(&mut context);

        // Assert: Should be StatusRequest, Target 10, ER flag true
        assert_eq!(service, RequestedServiceId::StatusRequest);
        assert_eq!(target, node_id);
        assert_eq!(er_flag, true);
        assert!(context.pending_er_requests.is_empty());
    }

    #[test]
    fn test_priority_status_requests() {
        let mut context = create_test_context();
        let node_id = NodeId(20);

        // Setup: Add a pending Status request
        context.pending_status_requests.push(node_id);

        // Act
        let (service, target, er_flag) = determine_next_async_action(&mut context);

        // Assert: Should be StatusRequest, Target 20, ER flag false
        assert_eq!(service, RequestedServiceId::StatusRequest);
        assert_eq!(target, node_id);
        assert_eq!(er_flag, false);
    }

    #[test]
    fn test_priority_nmt_command_over_generic() {
        let mut context = create_test_context();
        let target_node = NodeId(5);

        // Setup: Add both an NMT command and a generic ASnd frame
        context.pending_nmt_commands.push((
            MnNmtCommandRequest::State(NmtStateCommand::StartNode),
            target_node,
            NmtCommandData::None,
        ));

        let dummy_frame = PowerlinkFrame::SoA(crate::frame::SoAFrame::new(
            Default::default(),
            NmtState::NmtOperational,
            Default::default(),
            RequestedServiceId::NoService,
            NodeId(0),
            crate::types::EPLVersion(0),
        ));
        context.mn_async_send_queue.push(dummy_frame);

        // Act
        let (service, target, _) = determine_next_async_action(&mut context);

        // Assert: NMT command (UnspecifiedInvite to Self) takes precedence
        assert_eq!(service, RequestedServiceId::UnspecifiedInvite);
        assert_eq!(target, NodeId(C_ADR_MN_DEF_NODE_ID));
        // Ensure the NMT command is still in the queue (it's consumed by tick/cycle, not scheduler)
        assert!(!context.pending_nmt_commands.is_empty());
    }

    #[test]
    fn test_priority_cn_async_request() {
        let mut context = create_test_context();
        let node_high = NodeId(10);
        let node_low = NodeId(11);

        // Setup: CN 10 requests with Priority 7 (NMT), CN 11 with Priority 3 (Generic)
        context.async_request_queue.push(AsyncRequest {
            node_id: node_low,
            priority: 3,
        });
        context.async_request_queue.push(AsyncRequest {
            node_id: node_high,
            priority: 7,
        });

        // Act 1: Should pick High Priority
        let (service1, target1, _) = determine_next_async_action(&mut context);
        assert_eq!(target1, node_high);
        assert_eq!(service1, RequestedServiceId::NmtRequestInvite);

        // Act 2: Should pick Low Priority
        let (service2, target2, _) = determine_next_async_action(&mut context);
        assert_eq!(target2, node_low);
        assert_eq!(service2, RequestedServiceId::UnspecifiedInvite);
    }

    #[test]
    fn test_find_next_node_to_identify() {
        let mut context = create_test_context();

        // Setup: Add nodes in various states
        // Node 1: Operational (Known)
        context.node_info.insert(
            NodeId(1),
            CnInfo {
                state: CnState::Operational,
                ..Default::default()
            },
        );
        // Node 2: Unknown (Needs ID)
        context.node_info.insert(
            NodeId(2),
            CnInfo {
                state: CnState::Unknown,
                ..Default::default()
            },
        );
        // Node 3: Missing (Needs ID to check if back)
        context.node_info.insert(
            NodeId(3),
            CnInfo {
                state: CnState::Missing,
                ..Default::default()
            },
        );

        // Act 1
        let node1 = find_next_node_to_identify(&mut context).unwrap();
        assert_eq!(node1, NodeId(2));

        // Act 2 (Round robin)
        let node2 = find_next_node_to_identify(&mut context).unwrap();
        assert_eq!(node2, NodeId(3));

        // Act 3 (Loop back to 2)
        let node3 = find_next_node_to_identify(&mut context).unwrap();
        assert_eq!(node3, NodeId(2));
    }

    #[test]
    fn test_find_next_async_only_to_poll() {
        let mut context = create_test_context();

        // Setup: Two async-only nodes
        context.async_only_nodes.push(NodeId(10));
        context.async_only_nodes.push(NodeId(20));

        context.node_info.insert(
            NodeId(10),
            CnInfo {
                state: CnState::Operational,
                ..Default::default()
            },
        );
        context.node_info.insert(
            NodeId(20),
            CnInfo {
                state: CnState::Operational,
                ..Default::default()
            },
        );

        // Act 1
        let node1 = find_next_async_only_to_poll(&mut context).unwrap();
        assert_eq!(node1, NodeId(10));

        // Act 2
        let node2 = find_next_async_only_to_poll(&mut context).unwrap();
        assert_eq!(node2, NodeId(20));

        // Act 3 (Loop back)
        let node3 = find_next_async_only_to_poll(&mut context).unwrap();
        assert_eq!(node3, NodeId(10));
    }
}
